{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a5b2b-934a-4a5e-9cfc-221a5f470a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7ff99-fc78-494c-9d86-e71d68563b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute paths to dataset directories\n",
    "real_dir = 'E:\\\\schoolprojects\\\\capstone\\\\dataset\\\\real'\n",
    "fake_dir = 'E:\\\\schoolprojects\\\\capstone\\\\dataset\\\\fakeV2\\\\fake-v2'\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce024e-9106-4681-9d9c-cd3c54d9ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 25\n",
    "BUFFER_SIZE = 70_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177398c-876f-4b86-820f-ef7380802cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display real image\n",
    "Image.open(real_dir + '\\\\0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80194fbd-9ae9-4f27-b24f-3af927b8e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display fake image\n",
    "Image.open(fake_dir + '\\\\10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbdc6b1-a66c-40fe-b5f7-f2d2ce850ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusts quality of image and converts to jpg\n",
    "def adjust_image_quality(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "        \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "        \n",
    "    \n",
    "    return temp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc221d5-f481-4e0c-b47d-8a864e773a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing adjust_image_quality\n",
    "image1 = adjust_image_quality(real_dir + '\\\\0.jpg', 80)\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4d326-4a72-4194-b24e-732f0b7dcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes to image size variable and flattens to array\n",
    "def prepare_image(path):\n",
    "    return np.array(adjust_image_quality(path, 80).resize(IMAGE_SIZE)).flatten()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534fe44-8b55-403c-bd18-70f36fd1d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images in image_array, labels in label array: 0 for fake and 1 for real\n",
    "image_array = []\n",
    "label_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35da411-829b-4968-b10b-c19a5243150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates through directory for jpgs and pngs and adds to image and label arrays,\n",
    "# real_or_fake should be a 0 for fake and 1 for real\n",
    "# Source from https://www.kaggle.com/code/maikonikkobanaag/dl-project-efficientnetb4\n",
    "# DL Project | EfficientNetB4\n",
    "def get_images(path, real_or_fake):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                full_path = os.path.join(dirname, filename)\n",
    "                image_array.append(prepare_image(full_path))\n",
    "                label_array.append(real_or_fake)\n",
    "                if len(label_array) % 1000 == 0:\n",
    "                    print(f'Processing {len(label_array)} images')\n",
    "                if len(label_array) == 10000:\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628262d-c898-4b60-93d3-132726a28b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build image array of real and fake images\n",
    "get_images(real_dir, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adabc5b-30f7-4261-9902-6acb28f9c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(fake_dir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4587a-4267-4fbf-a963-01890e4c4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save np arrays for future use without having to get_images each time\n",
    "np.save(\"image_array_file\", image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc9f39-6c8f-451b-8c85-89387fffc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"label_array_file\", label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa751915-c360-433f-9f66-193824681f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load np arrays\n",
    "image_array = np.load(\"image_array_file.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21596ea1-7a1f-4650-9cfc-1ca9403b1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.load(\"label_array_file.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460ba5b-2917-4e36-be01-258562f07dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d723827-c181-4f64-b3df-c308dfb758c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm length of arrays\n",
    "len(image_array)\n",
    "len(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcca75d-b3b1-4dc9-9a78-acecd27a2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format arrays\n",
    "image_array = np.array(image_array)\n",
    "image_array = image_array.reshape(-1, 128, 128, 3)\n",
    "label_array = to_categorical(label_array, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab7a48-76ca-4865-951b-9906522bb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets\n",
    "image_train, image_valid, label_train, label_valid = train_test_split(image_array, label_array, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac7048-5573-4515-bcd7-cb85d1562765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard image_array\n",
    "image_array = image_array.reshape(-1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7632e-f2f8-472b-931a-b2c02314b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm length of training and validation data\n",
    "print(len(image_train), len(label_train))\n",
    "print(len(image_valid), len(label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7171a40-2265-4e06-b437-a6c3882a009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(128,128,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699e218-24ef-4928-94d3-be115e990730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae87fdd-076e-4d51-a38d-ab8d7ea6891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31061420-97ed-4770-8f78-b66cd9a497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063480c9-9a82-4f60-bac4-1a50f6c92f7a",
   "metadata": {},
   "source": [
    "## Callbacks + Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d8c56-9957-4bce-8fb7-0ca1463ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87130719-8832-421d-ae28-08b8d0a5fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb376835-e66d-4cf4-a4d6-ddb43808d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator definition \n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b9d22-8fd7-42ce-8cb4-9df5a58d3b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "hist = model.fit(\n",
    "    datagen.flow(image_train, label_train, batch_size = BATCH_SIZE),\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [tensorboard_callback, early_stopping],\n",
    "    validation_data = (image_valid, label_valid),\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf1efb-654a-4c3a-87c3-1050fa2395e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_24-3-19.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceeffac-68c4-4867-a01c-312f4b0ca834",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf28cc5-08d7-4ef0-9226-db7e1f0be457",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir \"logs/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fa56b-c226-49df-841f-be5c7730deb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "073f1ed1-746d-4aab-983c-f88789ca81cc",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f5f2b-e083-42d6-9f1b-3dc1e9d6bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source from https://www.kaggle.com/code/maikonikkobanaag/dl-project-efficientnetb4\n",
    "# DL Project | EfficientNetB4\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(hist.history['val_accuracy'], color='r', label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68695496-66a6-47d5-a712-483bf7c28870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source from https://www.kaggle.com/code/maikonikkobanaag/dl-project-efficientnetb4\n",
    "# DL Project | EfficientNetB4\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          matrix_cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=matrix_cmap)  # Use matrix_cmap for the matrix\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440426d-3342-4369-b917-91efc361e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(image_valid)\n",
    "label_pred_classes = np.argmax(label_pred,axis=1) \n",
    "label_true = np.argmax(label_valid,axis=1) \n",
    "confusion_mtx = confusion_matrix(label_true, label_pred_classes) \n",
    "plot_confusion_matrix(confusion_mtx, classes=range(2), matrix_cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905feeea-5886-4021-b6a9-74ada71f8d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
